---
title: "NRES 776 Lecture 17"
subtitle: "GLM - Poisson regression"
author: Sunny Tseng
format:
  revealjs: 
    slide-number: true
    preview-links: auto
    #css: styles.css
    #footer: <https://quarto.org>
    theme: [default, styles.scss]
    #smaller: true
    #scrollable: true
    incremental: true
    embed-resources: true
    width: 1200
    fontsize: 1.7em
editor: visual
---

```{r setup}
library(tidyverse)
library(here)
```

## Our schedule today

-   Announcement (5 min)

-   Review of LM and GLM (12 min)

-   Poisson regression (20 min)

-   Wrap up (5 min)

## Announcement

::: aside
Artwork by @allison_horst
:::

## Generalized linear model (GLM)

> GLM is a statistical modelling technique formulated by John Nelder and Robert Wedderburn. It allows the response variable $y$ to have an error distribution other than a normal distribution.The models include Linear Regression, Logistic Regression, and Poisson Regression.

-   Generalized: GLM can accommodates other error structures (e.g., Poisson, Binomial) in addition to Normal

-   Linear: The parameters, coefficients (i.e., $\beta$) are linearly combined

![](images/Capture.PNG){fig-align="center" width="666"}

::: aside
https://www.youtube.com/watch?app=desktop&v=ddCO2714W-o
:::

## Count data follows Poisson distribution

-   Scores, number of vehicles, number of individuals within certain area and time

-   Count data follows Poisson distribution $(0, \infty)$, which only has one parameter $\lambda$

-   The mean is equal to variance, both are $\lambda$

$$
P(x) = \frac{\lambda^x e^{-\lambda}}{x!}
$$

::: columns
::: {.column width="50%"}
![](images/SimÃ©onDenisPoisson.jpg){fig-align="center" width="335"}
:::

::: {.column width="50%"}

![](images/Poisson_pmf.svg.png){fig-align="center" width="418"}
:::
:::

## GLM for Poisson

**When to use**: $y$ is count (no natural denominator, else use y as a proportion)

1.  Systematic component

$$ \eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi} $$

2.  Link function $g()$ --\> most often **log,** makes $(0, \infty)$ to $(-\infty, \infty)$

$$ \eta_i = g(\lambda_i) = log(\lambda_i) $$

3.  Random component

$$ var(y_i) = n_ip_i(1-p_i) $$

## What we learned today

-   GLM is the generalized version of linear model where the distribution of $y$ can be any exponential family

-   Linear model is a special case of generalized linear model, when $y$ is normally distributed

-   We can use `glm()` in R, specifying `family = gaussian`, and get the same result as `lm()`

-   Use GLM according to the distribution of $y$, if possible. Better than transforming variables to fit linear model assumptions

-   Choose proper GLM (distribution and link) by data type

## Wrap up

### Before we meet again

-   

### Next time

-   Thursday lecture (Nov.2, 12:30) virtual on zoom -\> UNBC classroom (?)
    -   We will focus on Poisson regression, one type of GLM
