---
title: "NRES 776 Lecture 17"
subtitle: "GLM - Poisson regression"
author: Sunny Tseng
format:
  revealjs: 
    slide-number: true
    preview-links: auto
    #css: styles.css
    #footer: <https://quarto.org>
    theme: [default, styles.scss]
    #smaller: true
    #scrollable: true
    incremental: true
    embed-resources: true
    width: 1200
    fontsize: 1.7em
editor: visual
---

```{r setup}
library(tidyverse)
library(here)
library(palmerpenguins)
library(lmtest)
```

## Our schedule today

-   Announcement (5 min)

-   Review of GLM (10 min)

-   Poisson regression (25 min)

-   Wrap up (5 min)

## Announcement

::: aside
Artwork by @allison_horst
:::

## Generalized linear model (GLM)

> GLM is a statistical modelling technique formulated by John Nelder and Robert Wedderburn. It allows the response variable $y$ to have an error distribution other than a normal distribution.The models include Linear Regression, Logistic Regression, and Poisson Regression.

-   Generalized: GLM can accommodates other error structures (e.g., Poisson, Binomial) in addition to Normal

-   Linear: The parameters, coefficients (i.e., $\beta$) are linearly combined

![](images/Capture.PNG){fig-align="center" width="666"}

::: aside
https://www.youtube.com/watch?app=desktop&v=ddCO2714W-o
:::

## Assumptions of GLM

-   Independent observation

-   The variance function (i.e., distribution type) is correctly specified

-   The link function is correctly specified

-   The dispersion parameter, or scale parameter ($\phi$) equals 1

    -   Over-dispersed ($\phi > 1$) or under-dispersed ($\phi < 1$)

    -   Can change the variance function to account for this (use `quasipoisson` or `quasibinomial`)

## Model goodness of fit

-   Better models have higher likelihood

-   Better models have higher Pseudo R-squared (interpretation of this is similar to the R-squared in linear models)

-   Better models have lower AIC value

-   Pearson residuals versus fitted values, or predictors. They should have no patterns

# Poisson regression

## Count data follows Poisson distribution

-   Scores, number of vehicles, number of individuals within certain area and time

-   Count data follows Poisson distribution $(0, \infty)$, which only has one parameter $\lambda$

-   The mean is equal to variance, both are $\lambda$

$$
P(x) = \frac{\lambda^x e^{-\lambda}}{x!}
$$

::: columns
::: {.column width="50%"}
![](images/SimÃ©onDenisPoisson.jpg){fig-align="center" width="335"}
:::

::: {.column width="50%"}
![](images/Poisson_pmf.svg.png){fig-align="center" width="418"}
:::
:::

## Overview of Poisson

1.  Systematic component

$$ \eta_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi} $$

2.  Link function $g()$ --\> most often **log,** makes $(0, \infty)$ to $(-\infty, \infty)$

$$ \eta_i = g(\lambda_i) = log(\lambda_i) $$

3.  Random component

$$ var(y_i) = \lambda = \mu $$

## Overview of Poisson (con'd)

$$ ln(\mu_i) = ln(\hat{y_i}) = \beta_0 + \beta_1 x_{1i} + ... + \beta_p x_{pi} $$

Family: Poisson; Link function: $log$ (the most commonly used)

**When to use**

-   $y$ is count (no natural denominator, else use $y$ as a proportion)

-   $y$ must be a variable that is counted within defined area and time

**Not to use**

-   $y$ is not count or non-positive

-   Non-constant sample area or time ($trees/km$ vs $trees/m$)

-   Mean count $\geq$ 30 -\> consider using normal distribution

-   Over-dispersed -\> consider quasi-Poisson

-   Too many zeros -\> consider zero-inflated Poisson

## Overview of Poisson (con'd)

-   By default `family = poisson(link = "log")`

-   You can change the link to `"identity"` or `"sqrt"`

-   The `variance = "mu"` for this distribution and you cannot change it from the default

```{r}
scores <- penguins %>%   
  complete(year, island, species) %>%   
  summarize(count = n(), .by = c(island, year, species)) %>%   
  select(species, count) %>%   
  arrange(species) %>%   
  rename(player = species, score = count) %>%   
  mutate(player = case_when(     
    player == "Adelie" ~ "Adam",     
    player == "Chinstrap" ~ "Cindy",     
    player == "Gentoo" ~ "Gilliam"))
```

```{r, echo = TRUE}
glm_poission <- glm(formula = score ~ player,
                    data = scores,                     
                    family = "poisson")  
glm_poission %>% summary
```

## Research question

There is a investigation on how the tension (Low, Median, or High) on the number of warp breaks per loom. The "breaks" is the response variable which is a count of number of breaks. And the tension (L, M, H) is taken as the predictor variable.

::: columns
::: {.column width="50%"}
```{r}
breaks_overview <- warpbreaks %>%
  select(-wool) %>%
  mutate(round = rep(seq(1:18), 3)) %>%
  pivot_wider(names_from = tension, values_from = breaks)
breaks_overview
```
:::

::: {.column width="50%"}
Take a look at the group means

```{r, echo = TRUE}
warpbreaks %>%
  summarize(mean_breaks = mean(breaks), 
            .by = tension)
```
:::
:::

## Model formulation

$$
ln(\mu_i) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i}
$$

```{r, echo = TRUE}
breaks_poisson <- glm(formula = breaks ~ tension, data = warpbreaks, family = "poisson")

breaks_poisson %>% summary
```

## Coef. interpretation

-   For Low tension:

$$
ln(\mu_i) = \beta_0
$$

$$
\mu_i = exp(\beta_0) = exp(3.59) = 36.38
$$

. . .

-   For Median tension:

$$
ln(\mu_i) = \beta_0 + \beta_1
$$

$$
\mu_i = exp(\beta_0 + \beta_1) = exp(3.59) * exp(-0.32) = 26.38
$$

. . .

-   For High tension:

$$
ln(\mu_i) = \beta_0 + \beta_2
$$

$$
\mu_i = exp(\beta_0 + \beta_2) = exp(3.59) * exp(-0.51) = 21.66
$$

## Output interpretation

### Group mean prediction

-   The predicted group means are the same as the ones we calculated based on data

### R output

-   **Intercept (3.59)**: The number of breaks for reference level (low tension) is $exp(3.59)$

-   **tensionM (-0.32)**: The number of breaks for median tension is $exp(-0.32)$ **times** less than reference level (low tension)

-   **tensionH (-0.51)**: The number of breaks for high tension is $exp(-0.51)$ **times** less than reference level (low tension)

-   **Dispersion parameter (1)**: wonderful. Need to consider other methods if dispersion larger than 1 (over-dispersion) or smaller than 1 (under-dispersion)

-   **AIC (507.09)**: Can be used to compare the goodness of fit between models

## Model goodness of fit: Likelihood ratio test

```{r, echo = TRUE}
breaks_poisson_null <- glm(formula = breaks ~ 1, 
                           data = warpbreaks,
                           family = "poisson")
```

$H_0$: The model performance is the same as a null model (making predictions by chance)

$H_1$: The model performance is significantly different comparing to a null model

. . .

-   Use `lrtest()` function in the `lmtest` package

```{r, echo = TRUE}
lrtest(breaks_poisson, breaks_poisson_null)
```

## Model goodness of fit: Likelihood ratio test

```{r, echo = TRUE}
breaks_poisson_null <- glm(formula = breaks ~ 1,
                           data = warpbreaks, 
                           family = "poisson")
```

$H_0$: The model performance is the same as a null model (making predictions by chance)

$H_1$: The model performance is significantly different comparing to a null model

. . .

-   Or, Use `anova()` and specify `test = "Chisq"`

```{r, echo = TRUE}
anova(breaks_poisson, breaks_poisson_null, test = "Chisq")
```

## Predictor significance: Likelihood ratio test

-   Test whether adding one more variable `wool` (type of wool) could increase the model performance

$H_0$: The full model performance is the same as a reduced model (whichever model have fewer predictors)

$H_1$: The full model performance is significantly different comparing to a reduced model

. . .

```{r, echo = TRUE}
breaks_poisson_add <- glm(formula = breaks ~ tension + wool, 
                           data = warpbreaks,
                           family = "poisson")

lrtest(breaks_poisson, breaks_poisson_add)
```

## Model prediction

-   Use `prediction()` and specify `type = "response"` to get back transformed $y_i$

```{r, echo = TRUE}

```

-   Or, use fitted(), which provides back transformed $y_i$ by default

```{r}

```

## Model visualization

-   Box plot: categorical (y: count; x = tension)

-   Smooth: continuous (y: count; x =

```{r, echo = TRUE}
ggplot(aes(x = tension, y = breaks), data = warpbreaks) +
  #geom_boxplot() + 
  geom_jitter(width = 0.05, height = 0.05) + 
  geom_smooth(method = "glm", method.arg = list(family = "poisson"))
```

## What we learned today

## Wrap up

### Before we meet again

-   

### Next time

-   Thursday lecture (Nov.2, 12:30) virtual on zoom -\> UNBC classroom (?)
    -   We will focus on Poisson regression, one type of GLM
